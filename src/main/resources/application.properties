spring.application.name=openai
logging.pattern.console=%green(%d{HH:mm:ss.SSS}) %blue(%-5level) %red([%thread]) %yellow(%logger{15}) - %msg%n
logging.level.org.springframework.ai.chat.client.advisor=DEBUG

spring.main.allow-bean-definition-overriding=true

spring.ai.openai.api-key=${OPENAI_API_KEY}
#spring.ai.model.chat=ollama
#spring.ai.ollama.chat.options.model=llama3.2:1b
#spring.ai.ollama.base-url=


# Docker Model Runner Config
#spring.ai.openai.chat.options.model=ai/gemma3
#spring.ai.openai.api-key=dummy
#spring.ai.openai.chat.base-url=http://localhost:12434/engines

# h2 database config
spring.datasource.url=jdbc:h2:file:D:\\Tech\\Spring AI\\chatmemory;AUTO_SERVER=true
spring.datasource.driver-class-name=org.h2.Driver
spring.datasource.username=madhan
spring.datasource.password=12345
spring.h2.console.enabled=true
spring.jpa.hibernate.ddl-auto=update

spring.ai.chat.memory.repository.jdbc.initialize-schema=always
spring.ai.chat.memory.repository.jdbc.schema=classpath:/schema/schema-h2db.sql

spring.docker.compose.stop.command=down

spring.ai.vectorstore.qdrant.initialize-schema=true
spring.ai.vectorstore.qdrant.host=localhost
spring.ai.vectorstore.qdrant.collection-name=dummy-collection